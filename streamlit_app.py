import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

def process_image(image):
    with mp_pose.Pose(static_image_mode=True) as pose:
        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if results.pose_landmarks:
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
    return image

st.set_page_config(page_title="MediaPipe Pose Estimation", layout="wide")
st.title("ğŸ¤¸ MediaPipe å§¿æ…‹ä¼°è¨ˆ")

option = st.radio("é¸æ“‡è¼¸å…¥æ–¹å¼", ['ä¸Šå‚³åœ–ç‰‡', 'ä¸Šå‚³å½±ç‰‡'])

if option == 'ä¸Šå‚³åœ–ç‰‡':
    uploaded_file = st.file_uploader("è«‹é¸æ“‡åœ–ç‰‡", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        file_bytes = uploaded_file.read()
        np_img = cv2.imdecode(np.frombuffer(file_bytes, np.uint8), cv2.IMREAD_COLOR)
        col1, col2 = st.columns(2)
        col1.image(np_img, caption='åŸå§‹åœ–ç‰‡', use_column_width=True)
        processed = process_image(np_img.copy())
        col2.image(processed, caption='å§¿æ…‹ä¼°è¨ˆçµæœ', use_column_width=True)

elif option == 'ä¸Šå‚³å½±ç‰‡':
    uploaded_video = st.file_uploader("è«‹ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()
        with mp_pose.Pose() as pose:
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                stframe.image(frame, channels="BGR", use_column_width=True)
        cap.release()
        os.unlink(tfile.name)

